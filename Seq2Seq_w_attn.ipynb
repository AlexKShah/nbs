{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Seq2Seq_w_attn.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPuXJV91l02J2wRVuGWtyQm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"5S3YCHYCyPAN","colab_type":"code","colab":{}},"source":["# Translation with Sequence to sequence with attention in Pytorch\n","# From examples, modified for new dataset by Alex Shah\n","# https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#sphx-glr-intermediate-seq2seq-translation-tutorial-py\n","# https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/seq2seq_translation_tutorial.ipynb\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","from io import open\n","import unicodedata\n","import string\n","import time\n","import random\n","import math\n","\n","SOS_token = 0\n","EOS_token = 1\n","MAX_LENGTH = 30\n","\n","#lang1, lang2 = \"eng\", \"spa\"\n","lang1, lang2 = \"eng\", \"fra\"\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n","        self.n_words = 2  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wkGC88tr9Ptm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"67afbf28-d051-405e-abb8-b67fcbe154c9","executionInfo":{"status":"ok","timestamp":1581110677897,"user_tz":300,"elapsed":343,"user":{"displayName":"Alex Shah","photoUrl":"https://lh4.googleusercontent.com/-RsFr5HVwv2o/AAAAAAAAAAI/AAAAAAAAAfY/RLxLuZawDBM/s64/photo.jpg","userId":"12103988032103255580"}}},"source":["test = \"Run!\t¡Corran!\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #5213896 (cueyayotl)\"\n","splittest = test.split('\\t')[:-1]\n","splittest"],"execution_count":125,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Run!', '¡Corran!']"]},"metadata":{"tags":[]},"execution_count":125}]},{"cell_type":"code","metadata":{"id":"IZBTg7wc-XpR","colab_type":"code","colab":{}},"source":["def cleanString(s):\n","  s = s.lower().strip()\n","  s.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","  return s\n","\n","def readInDS(lang1, lang2):\n","  lines = open('/content/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n","        read().strip().split('\\n')\n","  pairs = [[cleanString(s) for s in l.split('\\t')[:2]] for l in lines]\n","  input_lang = Lang(lang1)\n","  output_lang = Lang(lang2)\n","  return input_lang, output_lang, pairs\n","\n","def filterPair(p):\n","    return len(p[0].split(' ')) < MAX_LENGTH and \\\n","        len(p[1].split(' ')) < MAX_LENGTH\n","\n","def filterPairs(pairs):\n","    return [pair for pair in pairs if filterPair(pair)]\n","\n","def preprocess(lang1, lang2):\n","  input_lang, output_lang, pairs = readInDS(lang1, lang2)\n","  pairs = filterPairs(pairs)\n","  for pair in pairs:\n","      input_lang.addSentence(pair[0])\n","      output_lang.addSentence(pair[1])\n","  print(input_lang.name, input_lang.n_words)\n","  print(output_lang.name, output_lang.n_words)\n","  return input_lang, output_lang, pairs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kS1dHOrb_h7q","colab_type":"code","colab":{}},"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","      super(EncoderRNN, self).__init__()\n","      self.hidden_size = hidden_size\n","      self.embedding = nn.Embedding(input_size, hidden_size)\n","      self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, input, hidden):\n","      embedded = self.embedding(input).view(1,1,-1)\n","      output = embedded\n","      output, hidden = self.gru(output, hidden)\n","      return output, hidden\n","\n","    def initHidden(self):\n","      return torch.zeros(1,1,self.hidden_size, device=device)\n","\n","#No attention\n","class DecoderRNN(nn.Module):\n","  def __init__(self, hidden_size, output_size):\n","    super(DecoderRNN, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.embedding = nn.Embedding(output_size, hidden_size)\n","    self.gru = nn.GRU(hidden_size, hidden_size)\n","    self.out = nn.Linear(hidden_size, output_size)\n","    self.softmax = nn.LogSoftmax(dim=1)\n","\n","  def forward(self, input, hidden):\n","    output = self.embedding(input).view(1,1,-1)\n","    output = F.relu(output)\n","    output, hidden = self.gru(output, hidden)\n","    output = self.softmax(self.out(output[0]))\n","    return output, hidden\n","\n","  def initHidden(self):\n","    return torch.zeros(1,1,self.hidden_size, device=device)\n","\n","#with attention\n","class AttentionDecoderRNN(nn.Module):\n","  def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","    super(AttentionDecoderRNN, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.output_size = output_size\n","    self.dropout_p = dropout_p\n","    self.max_length = max_length\n","    self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","    self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","    self.attn_combo = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","    self.dropout = nn.Dropout(self.dropout_p)\n","    self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","    self.out = (self.hidden_size, self.output_size)\n","\n","  def forward(self, input, hidden, encoder_outputs):\n","    embedded = self.embedding(input).view(1,1,-1)\n","    embedded = self.dropout(embedded)\n","    attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","    attn_made = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n","    output = torch.cat((embedded[0], attn_made[0]), 1)\n","    output = self.attn_combo(output).unsqueeze(0)\n","    output = F.relu(output)\n","    output, hidden = self.gru(output, hidden)\n","    output = F.log_softmax(self.out(output[0]), dim=1)\n","    return output, hidden, attn_weights\n","\n","  def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KL4dgaU_l_f6","colab_type":"code","colab":{}},"source":["class AttnDecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        attn_weights = F.softmax(\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs.unsqueeze(0))\n","\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden, attn_weights\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9q6Sl29gDLKu","colab_type":"code","colab":{}},"source":["def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","\n","def tensorFromSentence(lang, sentence):\n","    indexes = indexesFromSentence(lang, sentence)\n","    indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","\n","def tensorsFromPair(pair):\n","    input_tensor = tensorFromSentence(input_lang, pair[0])\n","    target_tensor = tensorFromSentence(output_lang, pair[1])\n","    return (input_tensor, target_tensor)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mMIXpwNjQ-Zm","colab_type":"code","colab":{}},"source":["def train(in_tensor, out_tensor, encoder, decoder, enc_opt, dec_opt, crit, max_length=MAX_LENGTH):\n","  enc_hidden = encoder.initHidden()\n","  enc_opt.zero_grad()\n","  dec_opt.zero_grad()\n","  in_length = in_tensor.size(0)\n","  out_length = out_tensor.size(0)\n","  enc_outs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","  loss = 0\n","\n","  for i in range(in_length):\n","    enc_out, enc_hidden = encoder(in_tensor[i], enc_hidden)\n","    enc_outs[i] = enc_out[0,0]\n","\n","  dec_in = torch.tensor([[SOS_token]], device=device)\n","  dec_hidden = enc_hidden\n","\n","  for i in range(out_length):\n","    dec_out, dec_hidden, dec_attn = decoder(dec_in, dec_hidden, enc_outs)\n","    kv, ki = dec_out.topk(1)\n","    dec_in = ki.squeeze().detach()\n","    loss += crit(dec_out, out_tensor[i])\n","    if dec_in.item() == EOS_token:\n","      break\n","    loss.backward()\n","    enc_opt.step()\n","    dec_opt.step()\n","    return loss.item()/out_length"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQ5Fx_MCUIET","colab_type":"code","colab":{}},"source":["def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sIZ3pGWlTyDe","colab_type":"code","colab":{}},"source":["def trainIters(encoder, decoder, n_iters, print_every=1000, learning_rate=0.01):\n","    start = time.time()\n","    print_loss_total = 0\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","    training_pairs = [tensorsFromPair(random.choice(pairs))\n","                      for i in range(n_iters)]\n","    criterion = nn.NLLLoss()\n","\n","    for iter in range(1, n_iters + 1):\n","        training_pair = training_pairs[iter - 1]\n","        input_tensor = training_pair[0]\n","        target_tensor = training_pair[1]\n","\n","        loss = train(input_tensor, target_tensor, encoder,\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print_loss_total += loss\n","\n","        if iter % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n","                                         iter, iter / n_iters * 100, print_loss_avg))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gIrktH3SUuYT","colab_type":"code","colab":{}},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n","  with torch.no_grad():\n","    input_tensor - tensorFromSentence(input_lang, sentence)\n","    input_length = input_tensor.size()[0]\n","    encoder_hidden = encoder.initHidden()\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","    for i in range(input_length):\n","      encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n","      encoder_outputs[i] += encoder_output[0,0]\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","    decoder_hidden = encoder_hidden\n","    decoded_words = []\n","    decoder_attn = torch.zeros(max_length, max_length)\n","\n","    for i in range(max_length):\n","      decoder_output, decoder_hidden, decoder_attn = decoder(decoder_input, decoder_hidden, encoder_outputs)\n","      decoder_attn[i] = decoder_attn.data\n","      kv, ki = deocder_output.data.topk(1)\n","      if ki.item() == EOS_token:\n","        decoded_words.append('<EOS>')\n","        break\n","      else:\n","        decoded_words.append(output_lang.index2word[ki.item()])\n","      decoder_input = ki.squeeze().detach()\n","    return decoded_words, decoder_attn[:i+1]\n","\n","  def randEval(encoder, decoder, num_examples=10):\n","    for i in range(num_examples):\n","      pair = random.choice(pairs)\n","      print(\" input: \", pair[0])\n","      print(\" actual: \", pair[1])\n","      output_words, attentions = evaluate(encoder, decoder, pair[0])\n","      output_sentence = ' '.join(output_words)\n","      print(\" predicted: \", output_sentence)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"73VKdiOZ-ssK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"6f2be002-1038-40d8-f2e4-ab470b7bd995","executionInfo":{"status":"error","timestamp":1581112604150,"user_tz":300,"elapsed":807218,"user":{"displayName":"Alex Shah","photoUrl":"https://lh4.googleusercontent.com/-RsFr5HVwv2o/AAAAAAAAAAI/AAAAAAAAAfY/RLxLuZawDBM/s64/photo.jpg","userId":"12103988032103255580"}}},"source":["hidden_size = 256\n","input_lang, output_lang, pairs = preprocess(lang1, lang2)\n","\n","encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n","\n","trainIters(encoder1, attn_decoder1, 75000, print_every=50)"],"execution_count":174,"outputs":[{"output_type":"stream","text":["eng 24405\n","fra 43119\n","0m 12s (- 300m 22s) (50 0%) 1.6795\n","0m 22s (- 277m 45s) (100 0%) 1.4003\n","0m 32s (- 271m 39s) (150 0%) 1.3989\n","0m 43s (- 271m 25s) (200 0%) 0.9451\n","0m 54s (- 270m 15s) (250 0%) 0.8853\n","1m 5s (- 270m 24s) (300 0%) 0.9102\n","1m 15s (- 268m 31s) (350 0%) 0.9599\n","1m 26s (- 267m 35s) (400 0%) 0.9003\n","1m 36s (- 266m 44s) (450 0%) 0.8138\n","1m 47s (- 266m 1s) (500 0%) 0.8133\n","1m 57s (- 265m 54s) (550 0%) 0.9971\n","2m 8s (- 265m 29s) (600 0%) 0.9661\n","2m 19s (- 266m 21s) (650 0%) 0.7322\n","2m 30s (- 267m 0s) (700 0%) 0.7396\n","2m 41s (- 265m 56s) (750 1%) 1.0041\n","2m 51s (- 265m 48s) (800 1%) 0.7909\n","3m 2s (- 265m 41s) (850 1%) 0.8473\n","3m 13s (- 265m 26s) (900 1%) 0.7899\n","3m 23s (- 264m 48s) (950 1%) 0.8639\n","3m 34s (- 263m 58s) (1000 1%) 0.7457\n","3m 44s (- 264m 4s) (1050 1%) 0.7844\n","3m 55s (- 263m 39s) (1100 1%) 0.9487\n","4m 5s (- 263m 0s) (1150 1%) 0.7112\n","4m 16s (- 263m 14s) (1200 1%) 0.8300\n","4m 27s (- 262m 50s) (1250 1%) 0.8937\n","4m 37s (- 262m 5s) (1300 1%) 1.0753\n","4m 47s (- 261m 43s) (1350 1%) 0.6931\n","4m 58s (- 261m 35s) (1400 1%) 0.6006\n","5m 9s (- 261m 23s) (1450 1%) 0.6709\n","5m 19s (- 261m 15s) (1500 2%) 0.8311\n","5m 30s (- 261m 20s) (1550 2%) 0.7382\n","5m 41s (- 260m 45s) (1600 2%) 0.7935\n","5m 51s (- 260m 15s) (1650 2%) 0.7372\n","6m 1s (- 260m 4s) (1700 2%) 0.8887\n","6m 12s (- 260m 2s) (1750 2%) 0.7859\n","6m 23s (- 259m 35s) (1800 2%) 0.8304\n","6m 34s (- 259m 39s) (1850 2%) 0.6339\n","6m 44s (- 259m 35s) (1900 2%) 0.8180\n","6m 55s (- 259m 28s) (1950 2%) 0.6351\n","7m 5s (- 259m 8s) (2000 2%) 0.8708\n","7m 16s (- 258m 58s) (2050 2%) 0.9424\n","7m 27s (- 258m 42s) (2100 2%) 0.7171\n","7m 38s (- 258m 54s) (2150 2%) 0.8526\n","7m 48s (- 258m 37s) (2200 2%) 0.6355\n","7m 59s (- 258m 38s) (2250 3%) 0.7176\n","8m 10s (- 258m 35s) (2300 3%) 0.7557\n","8m 21s (- 258m 12s) (2350 3%) 0.8515\n","8m 31s (- 258m 3s) (2400 3%) 0.7515\n","8m 42s (- 257m 43s) (2450 3%) 0.7221\n","8m 52s (- 257m 16s) (2500 3%) 0.7987\n","9m 2s (- 257m 2s) (2550 3%) 0.7313\n","9m 13s (- 256m 53s) (2600 3%) 0.7967\n","9m 24s (- 256m 39s) (2650 3%) 0.7541\n","9m 34s (- 256m 24s) (2700 3%) 0.7320\n","9m 45s (- 256m 10s) (2750 3%) 0.6414\n","9m 55s (- 256m 3s) (2800 3%) 0.6556\n","10m 6s (- 255m 59s) (2850 3%) 0.9045\n","10m 17s (- 256m 0s) (2900 3%) 0.6428\n","10m 28s (- 255m 52s) (2950 3%) 0.6160\n","10m 38s (- 255m 27s) (3000 4%) 1.0250\n","10m 49s (- 255m 15s) (3050 4%) 0.6648\n","11m 0s (- 255m 9s) (3100 4%) 0.7668\n","11m 10s (- 254m 58s) (3150 4%) 0.5481\n","11m 21s (- 254m 44s) (3200 4%) 0.6467\n","11m 31s (- 254m 36s) (3250 4%) 0.6886\n","11m 42s (- 254m 19s) (3300 4%) 0.6820\n","11m 52s (- 254m 6s) (3350 4%) 0.8158\n","12m 3s (- 253m 53s) (3400 4%) 0.7676\n","12m 14s (- 253m 47s) (3450 4%) 0.6011\n","12m 24s (- 253m 34s) (3500 4%) 0.7825\n","12m 35s (- 253m 24s) (3550 4%) 0.7981\n","12m 45s (- 253m 7s) (3600 4%) 0.6378\n","12m 56s (- 253m 0s) (3650 4%) 0.8395\n","13m 6s (- 252m 45s) (3700 4%) 0.7708\n","13m 17s (- 252m 33s) (3750 5%) 0.5869\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-174-00d026764e03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-131-e373a03536b1>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, learning_rate)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         loss = train(input_tensor, target_tensor, encoder,\n\u001b[0;32m---> 17\u001b[0;31m                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-142-d853ffc6ff63>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(in_tensor, out_tensor, encoder, decoder, enc_opt, dec_opt, crit, max_length)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdec_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEOS_token\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0menc_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mdec_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}